<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Create an llm_break_soft object — llm_break_soft • tidyprompt</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Create an llm_break_soft object — llm_break_soft"><meta name="description" content="This object is used to break a extraction and validation loop defined in a prompt_wrap(),
as evaluated by send_prompt(). When an extraction or validation function returns
this object, it will prevent any future interactions with the LLM provider for the
current prompt. Remaining extraction and validation functions will still be applied
and it will still be possible to pass these with the current response from the LLM
provider; only, no more new tries will be made if the current response is not
satisfactory.
This is useful when, e.g., the token limit for the LLM provider has been reached,
but the final response that we got may still be satisfactory. In this case,
llm_break() cannot be used, as it would instantly return the current response as the final
result, which is not what we want. Instead, llm_break_soft() can be used to
prevent any further interactions with the LLM provider, but still allow the
remaining extraction and validation functions to be applied (and have those decide
the success of the current response)."><meta property="og:description" content="This object is used to break a extraction and validation loop defined in a prompt_wrap(),
as evaluated by send_prompt(). When an extraction or validation function returns
this object, it will prevent any future interactions with the LLM provider for the
current prompt. Remaining extraction and validation functions will still be applied
and it will still be possible to pass these with the current response from the LLM
provider; only, no more new tries will be made if the current response is not
satisfactory.
This is useful when, e.g., the token limit for the LLM provider has been reached,
but the final response that we got may still be satisfactory. In this case,
llm_break() cannot be used, as it would instantly return the current response as the final
result, which is not what we want. Instead, llm_break_soft() can be used to
prevent any further interactions with the LLM provider, but still allow the
remaining extraction and validation functions to be applied (and have those decide
the success of the current response)."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyprompt</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.1.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/creating_prompt_wraps.html">Creating prompt wraps</a></li>
    <li><a class="dropdown-item" href="../articles/getting_started.html">Getting started</a></li>
    <li><a class="dropdown-item" href="../articles/sentiment_analysis.html">Sentiment analysis in R with a LLM and 'tidyprompt'</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tjarkvandemerwe/tidyprompt/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Create an <code>llm_break_soft</code> object</h1>
      <small class="dont-index">Source: <a href="https://github.com/tjarkvandemerwe/tidyprompt/blob/main/R/llm_break.R" class="external-link"><code>R/llm_break.R</code></a></small>
      <div class="d-none name"><code>llm_break_soft.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>This object is used to break a extraction and validation loop defined in a <code><a href="prompt_wrap.html">prompt_wrap()</a></code>,
as evaluated by <code><a href="send_prompt.html">send_prompt()</a></code>. When an extraction or validation function returns
this object, it will prevent any future interactions with the LLM provider for the
current prompt. Remaining extraction and validation functions will still be applied
and it will still be possible to pass these with the current response from the LLM
provider; only, no more new tries will be made if the current response is not
satisfactory.</p>
<p>This is useful when, e.g., the token limit for the LLM provider has been reached,
but the final response that we got may still be satisfactory. In this case,
<code><a href="llm_break.html">llm_break()</a></code> cannot be used, as it would instantly return the current response as the final
result, which is not what we want. Instead, <code>llm_break_soft()</code> can be used to
prevent any further interactions with the LLM provider, but still allow the
remaining extraction and validation functions to be applied (and have those decide
the success of the current response).</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">llm_break_soft</span><span class="op">(</span>object_to_return <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-object-to-return">object_to_return<a class="anchor" aria-label="anchor" href="#arg-object-to-return"></a></dt>
<dd><p>The object to return as the response result
from <code><a href="send_prompt.html">send_prompt()</a></code> when this object is returned from an extraction or
validation function</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>An list of class "llm_break_soft" containing the object to return</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># Quitting when total token count is exceeded (Google Gemini API example)</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span>  <span class="st">"How are you?"</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="co"># Forcing multi-response via initial error, for demonstration purposes</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="answer_as_integer.html">answer_as_integer</a></span><span class="op">(</span>add_instruction_to_prompt <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="co"># Validation function to check total token count</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="prompt_wrap.html">prompt_wrap</a></span><span class="op">(</span>validation_fn <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">response</span>, <span class="va">llm_provider</span>, <span class="va">http_list</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>      <span class="va">total_tokens</span> <span class="op">&lt;-</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map_dbl</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>        <span class="va">http_list</span><span class="op">$</span><span class="va">responses</span>,</span></span>
<span class="r-in"><span>        <span class="op">~</span> <span class="va">.x</span><span class="op">$</span><span class="va">body</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>          <span class="fu"><a href="https://rdrr.io/r/base/rawConversion.html" class="external-link">rawToChar</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>          <span class="fu">jsonlite</span><span class="fu">::</span><span class="fu"><a href="https://jeroen.r-universe.dev/jsonlite/reference/fromJSON.html" class="external-link">fromJSON</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>          <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/pluck.html" class="external-link">pluck</a></span><span class="op">(</span><span class="st">"usageMetadata"</span>, <span class="st">"totalTokenCount"</span><span class="op">)</span></span></span>
<span class="r-in"><span>      <span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span>      <span class="kw">if</span> <span class="op">(</span><span class="va">total_tokens</span> <span class="op">&gt;</span> <span class="fl">50</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>        <span class="kw"><a href="https://rdrr.io/r/base/warning.html" class="external-link">warning</a></span><span class="op">(</span><span class="st">"Token count exceeded; preventing further interactions"</span><span class="op">)</span></span></span>
<span class="r-in"><span>        <span class="co"># Using llm_break_soft() to prevent further interactions</span></span></span>
<span class="r-in"><span>        <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">llm_break_soft</span><span class="op">(</span><span class="va">response</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span>      <span class="op">}</span></span></span>
<span class="r-in"><span>    <span class="op">}</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="send_prompt.html">send_prompt</a></span><span class="op">(</span><span class="fu"><a href="llm_provider_google_gemini.html">llm_provider_google_gemini</a></span><span class="op">(</span><span class="op">)</span>, return_mode <span class="op">=</span> <span class="st">"full"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Luka Koning, Tjark Van de Merwe, Kennispunt Twente.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer></div>





  </body></html>

